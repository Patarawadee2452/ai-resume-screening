import json
from pathlib import Path
import streamlit as st
import pandas as pd
import numpy as np
import joblib
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer
import re
import smtplib
from email.mime.text import MIMEText
from email.utils import formataddr, formatdate, make_msgid
import textwrap
from tempfile import NamedTemporaryFile
import os
import time

try:
    import fitz
    PDF_OK = True
except Exception:
    PDF_OK = False

HR_USERS = {
    "hr01": "1234",
    "admin": "admin123"
}

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
    st.session_state.username = ""

def login_page():
    st.markdown("## üîê HR Login")
    u = st.text_input("Username")
    p = st.text_input("Password", type="password")

    if st.button("Login", type="primary"):
        if u in HR_USERS and HR_USERS[u] == p:
            st.session_state.logged_in = True
            st.session_state.username = u
            st.success("‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            st.rerun()
        else:
            st.error("Username ‡∏´‡∏£‡∏∑‡∏≠ Password ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

def logout():
    st.session_state.logged_in = False
    st.session_state.username = ""
    st.rerun()

st.set_page_config(page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ AI", page_icon="üìÑ", layout="wide")

if not st.session_state.logged_in:
    login_page()
    st.stop()

BASE_DIR = Path(__file__).parent.resolve()
MODEL_DIR = BASE_DIR / "models"
OUTPUT_DIR = BASE_DIR / "outputs"
MODEL_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

if "pass_cut" not in st.session_state:
    st.session_state["pass_cut"] = 0.5

# ---------- helpers ----------
def normalize_text(text):
    if not isinstance(text, str): return ""
    text = text.lower()
    text = re.sub(r"\s+", " ", text).strip()
    return text

def thai_tokenize(text):
    text = normalize_text(text)
    if not text: return []
    try:
        from pythainlp import word_tokenize
        return [t for t in word_tokenize(text, keep_whitespace=False) if t.strip()]
    except Exception:
        return text.split()

def encode_education(level):
    if not isinstance(level, str): return 0
    s = normalize_text(level)
    mapping = {
        "‡∏°‡∏±‡∏ò‡∏¢‡∏°":0,"‡∏°.6":0,"‡∏õ‡∏ß‡∏ä":0,"hs":0,"high school":0,
        "‡∏õ‡∏ß‡∏™":1,"‡∏≠‡∏ô‡∏∏‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤":1,"bachelor":1,"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ":1,"ba":1,"b.sc":1,"b.eng":1,
        "master":2,"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÇ‡∏ó":2,"m.sc":2,"mba":2,
        "phd":3,"doctorate":3,"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÄ‡∏≠‡∏Å":3
    }
    return mapping.get(s, mapping.get(s.title(), 0))

def split_skills(skills):
    if not isinstance(skills, str): return []
    return [s.strip().lower() for s in re.split(r"[,/;|\n]", skills) if s.strip()]

def concat_text_df(df, fields):
    cols = [c for c in fields if c in df.columns]
    if not cols: return pd.Series([""] * len(df))
    return df[cols].apply(lambda r: " ".join((str(r[c]).lower() if isinstance(r[c], str) else str(r[c])) for c in cols), axis=1)

def extract_text_from_pdf(uploaded_file):
    if not PDF_OK: return ""
    try:
        uploaded_file.seek(0)
        text = ""
        with fitz.open(stream=uploaded_file.read(), filetype="pdf") as doc:
            if doc.is_encrypted:
                try: doc.authenticate("")
                except Exception: pass
            for page in doc:
                text += page.get_text("text")
        return text.strip()
    except Exception as e:
        st.warning(f"‡∏≠‡πà‡∏≤‡∏ô PDF ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        return ""

class EducationEncoder(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None): return self
    def transform(self, X):
        return X["education_level"].apply(encode_education).astype(float).values.reshape(-1, 1)

def combine_exp_func(arr):
    if hasattr(arr, "__dataframe__") or isinstance(arr, pd.DataFrame):
        y = pd.to_numeric(arr.get("years_experience", 0), errors="coerce").fillna(0)
        m = pd.to_numeric(arr.get("months_experience", 0), errors="coerce").fillna(0)
        return (y + m/12.0).values.reshape(-1,1)
    a = np.asarray(arr)
    y = pd.to_numeric(pd.Series(a[:,0]), errors="coerce").fillna(0)
    m = pd.to_numeric(pd.Series(a[:,1] if a.shape[1]>1 else 0), errors="coerce").fillna(0)
    return np.asarray(y+m/12.0).reshape(-1,1)

def safe_load_joblib(p):
    try: return joblib.load(p)
    except Exception: return None

def atomic_joblib_dump(obj, path, compress=3):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with NamedTemporaryFile(delete=False, dir=os.path.dirname(path), suffix=".tmp") as t:
        tmp = t.name
    try:
        joblib.dump(obj, tmp, compress=compress)
        os.replace(tmp, path)
    finally:
        if os.path.exists(tmp):
            try: os.remove(tmp)
            except Exception: pass

# email clean/validate
WS_EDGES = re.compile(r'^\s+|\s+$', flags=re.UNICODE)
INVISIBLE = {"\u200b", "\ufeff"}
WIDE_SPACES = {"\u00a0", "\u202f", "\u2007", "\u2009", "\u200a", "\u205f", "\u3000"}
EMAIL_RE = re.compile(r"^[A-Za-z0-9._%+\-]+@[A-Za-z0-9.\-]+\.[A-Za-z]{2,}$")
BLOCKED_DEMO_DOMAINS = {"example.com","test.com","invalid","example.org","example.net"}

def clean_email(s):
    if not isinstance(s, str): return ""
    for ch in INVISIBLE: s = s.replace(ch, "")
    for ch in WIDE_SPACES: s = s.replace(ch, " ")
    return WS_EDGES.sub("", s)

def is_valid_email(s):
    s = clean_email(s)
    if not s or not EMAIL_RE.match(s): return False
    return s.split("@")[-1].lower() not in BLOCKED_DEMO_DOMAINS

# ---------- configs ----------
DEPARTMENTS_CFG = {
    "Audit": {"must_have_skills":["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏µ","‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô","excel ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á","‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏ö"],
              "nice_to_have_skills":["‡∏£‡∏∞‡∏ö‡∏ö erp","‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£","‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à"],
              "min_years_experience":1,"min_education_level":"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ",
              "knockout_phrases":["‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏á‡∏≤‡∏ô‡∏ã‡πâ‡∏≥","‡πÑ‡∏°‡πà‡∏ñ‡∏ô‡∏±‡∏î‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç","‡∏ä‡∏≠‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"],
              "age_range":[25,35],
              "activity_weights":{"‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ç‡∏ä‡∏µ":0.3,"‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡πÅ‡∏ú‡∏ô‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à":0.3,"‡πÅ‡∏Ç‡πà‡∏á‡πÅ‡∏ú‡∏ô‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à":0.3,"business plan":0.3,"‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ö‡∏±‡∏ç‡∏ä‡∏µ":0.4,"‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏±‡∏ç‡∏ä‡∏µ":0.4,"internship accounting firm":0.4,"internship audit":0.4},
              "max_activity_bonus":0.8},
    "Purchasing China": {"must_have_skills":["‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤","‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤","‡∏†‡∏≤‡∏©‡∏≤‡∏à‡∏µ‡∏ô","‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©","‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"],
              "nice_to_have_skills":["‡πÇ‡∏•‡∏à‡∏¥‡∏™‡∏ï‡∏¥‡∏Å‡∏™‡πå","erp","‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô"],
              "min_years_experience":2,"min_education_level":"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ",
              "knockout_phrases":["‡πÑ‡∏°‡πà‡∏ñ‡∏ô‡∏±‡∏î‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Ñ‡∏ô‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥","‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏ï‡πà‡∏≠‡∏£‡∏≠‡∏á","‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤"],
              "age_range":[25,38],
              "activity_weights":{"‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥":0.4,"‡πÄ‡∏õ‡πá‡∏ô‡∏•‡πà‡∏≤‡∏°":0.5,"‡∏•‡πà‡∏≤‡∏°‡∏à‡∏µ‡∏ô":0.5,"‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏µ‡∏ô":0.5,"exchange china":0.5,"‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏µ‡∏ô":0.5,"‡∏•‡πà‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡∏à‡∏µ‡∏ô":0.5},
              "max_activity_bonus":1.0},
    "Accounting": {"must_have_skills":["‡∏ó‡∏≥‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô","‡∏ó‡∏≥‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô","‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô","‡∏†‡∏≤‡∏©‡∏µ‡∏ã‡∏∑‡πâ‡∏≠","‡∏†‡∏≤‡∏©‡∏µ‡∏Ç‡∏≤‡∏¢","excel","express","sap"],
              "nice_to_have_skills":["power bi","‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô","‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©"],
              "min_years_experience":1,"min_education_level":"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ",
              "activity_weights":{"‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ö‡∏±‡∏ç‡∏ä‡∏µ":0.3,"internship accounting firm":0.3},
              "age_range":[22,35],"max_activity_bonus":0.6},
    "Human Resources": {"must_have_skills":["‡∏™‡∏£‡∏£‡∏´‡∏≤","‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå","‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô","‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô","‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏î‡∏µ"],
              "nice_to_have_skills":["hrm","‡∏à‡∏¥‡∏ï‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤","od"],
              "min_years_experience":1,"min_education_level":"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ",
              "knockout_phrases":["‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡πÄ‡∏à‡∏≠‡∏Ñ‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞","‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£","‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß"],
              "age_range":[24,40],
              "activity_weights":{"‡∏ä‡∏°‡∏£‡∏°‡∏ú‡∏π‡πâ‡∏ô‡∏≥":0.4,"‡∏ú‡∏π‡πâ‡∏ô‡∏≥":0.4,"‡∏≠‡∏≤‡∏™‡∏≤":0.4,"‡∏à‡∏¥‡∏ï‡∏≠‡∏≤‡∏™‡∏≤":0.4,"‡∏à‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏¢":0.4,"‡∏Ñ‡πà‡∏≤‡∏¢":0.3,"camp organizer":0.4},
              "max_activity_bonus":1.2},
    "Programmer": {"must_have_skills":["php","python","javascript","sql","debugging","agile"],
              "nice_to_have_skills":["ux/ui","cloud","aws","azure","cybersecurity"],
              "min_years_experience":0,"min_education_level":"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ",
              "knockout_phrases":["‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡∏°","‡πÑ‡∏°‡πà‡∏ñ‡∏ô‡∏±‡∏î‡πÅ‡∏Å‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô","‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÉ‡∏´‡∏°‡πà"],
              "age_range":[21,35],
              "activity_weights":{"‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå":0.6,"project":0.6,"hackathon":0.6,"‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°":0.6,"open source":0.6,"github":0.5,"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ":0.6,"web app":0.5,"mobile app":0.5},
              "max_activity_bonus":1.2},
    "Marketing": {"must_have_skills":["‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î","‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå","facebook ads","google ads","‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"],
              "nice_to_have_skills":["‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û","‡∏ï‡∏±‡∏î‡∏ï‡πà‡∏≠","seo","sem","analytics"],
              "min_years_experience":1,"min_education_level":"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ",
              "knockout_phrases":["‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡πÉ‡∏ä‡πâ‡πÇ‡∏ã‡πÄ‡∏ä‡∏µ‡∏¢‡∏•","‡πÑ‡∏°‡πà‡πÄ‡∏Å‡πà‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç","‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"],
              "age_range":[22,35],
              "activity_weights":{"‡∏ó‡∏≥‡πÄ‡∏û‡∏à":0.5,"‡πÄ‡∏û‡∏à":0.3,"‡∏ó‡∏≥‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå":0.5,"content creator":0.5,"‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ï‡∏á‡∏≤‡∏ô‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢":0.5,"‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå":0.4,"‡∏ó‡∏≥‡∏™‡∏∑‡πà‡∏≠":0.4,"admin page":0.4},
              "max_activity_bonus":1.2},
    "Delivery": {"must_have_skills":["‡∏£‡∏π‡πâ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏Ç‡∏ô‡∏™‡πà‡∏á","‡∏à‡∏±‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡πà‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤","‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏ô‡∏™‡πà‡∏á"],
              "nice_to_have_skills":["gps","‡πÉ‡∏ö‡∏Ç‡∏±‡∏ö‡∏Ç‡∏µ‡πà","‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏•‡∏±‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"],
              "min_years_experience":1,"min_education_level":"‡∏õ‡∏ß‡∏ä",
              "activity_weights":{"‡∏û‡∏≤‡∏£‡πå‡∏ó‡πÑ‡∏ó‡∏°‡πå‡∏Ç‡∏ô‡∏™‡πà‡∏á":0.3,"part-time delivery":0.3,"rider":0.3,"‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô‡πÇ‡∏•‡∏à‡∏¥‡∏™‡∏ï‡∏¥‡∏Å‡∏™‡πå":0.3},
              "age_range":[22,40],"max_activity_bonus":0.6},
    "Warehouse": {"must_have_skills":["‡∏ï‡∏£‡∏ß‡∏à‡∏ô‡∏±‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤","‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏ï‡πá‡∏≠‡∏Å","‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏Ñ‡∏•‡∏±‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"],
              "nice_to_have_skills":["‡πÇ‡∏ü‡∏•‡πå‡∏Å‡∏•‡∏¥‡∏ü‡∏ï‡πå","fifo","‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"],
              "min_years_experience":1,"min_education_level":"‡∏õ‡∏ß‡∏ä",
              "activity_weights":{"‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏•‡∏±‡∏á":0.2,"‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤":0.2,"‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô‡∏Ñ‡∏•‡∏±‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤":0.3,"inventory project":0.2},
              "age_range":[20,40],"max_activity_bonus":0.5}
}

DEFAULT_RULES = {
    "rule_weights":{"exp_under":-1.0,"exp_meet":0.2,"edu_under":-1.0,"must_missing":-1.5,"must_all":0.5,
                    "knockout":-2.0,"nice_each":0.3,"training_ctx":-0.5,"low_exp_skill":-0.3,"age_out":-1.0,"age_in":0.2},
    "training_indicators":["‡∏≠‡∏ö‡∏£‡∏°","‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤","‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏ä‡∏≠‡∏õ","workshop","training","‡∏Ñ‡∏≠‡∏£‡πå‡∏™","course","certificate","certification"],
    "activity_weights":{},"max_activity_bonus":0.0,"default_age_range":[18,60],
    "global_knockout":{"hard":["‡∏î‡πà‡∏≤‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÄ‡∏Å‡πà‡∏≤","‡∏î‡πà‡∏≤‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏Å‡πà‡∏≤","‡πÇ‡∏Å‡∏á","‡∏ó‡∏∏‡∏à‡∏£‡∏¥‡∏ï","‡∏õ‡∏•‡∏≠‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£","‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ú‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó","‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤","‡∏Å‡πâ‡∏≤‡∏ß‡∏£‡πâ‡∏≤‡∏ß","‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á"],
                       "soft":["‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡∏°","‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡πÄ‡∏à‡∏≠‡∏Ñ‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞","‡πÑ‡∏°‡πà‡∏ñ‡∏ô‡∏±‡∏î‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç","‡∏°‡∏≤‡∏™‡∏≤‡∏¢‡∏ö‡πà‡∏≠‡∏¢","‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏•‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤","‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î","‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏á‡∏≤‡∏ô‡∏ã‡πâ‡∏≥ ‡πÜ","‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°","‡πÑ‡∏°‡πà‡∏ñ‡∏ô‡∏±‡∏î‡πÅ‡∏Å‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô","‡πÑ‡∏°‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î","‡πÑ‡∏°‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏ö"],
                       "review":["‡∏•‡∏≤‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß","‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏±‡∏ö‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏Å‡πà‡∏≤","‡∏•‡∏≤‡∏≠‡∏≠‡∏Å‡∏ó‡∏±‡∏ô‡∏ó‡∏µ","‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ô‡∏≤‡∏ô"]},
    "global_knockout_weights":{"hard":-2.0,"soft":-1.0,"review":0.0},
    "global_knockout_cap":-2.5,
    "global_mitigation":{"whitelist_phrases":["‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏°‡πà‡∏ñ‡∏ô‡∏±‡∏î‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÅ‡∏ï‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏±‡∏í‡∏ô‡∏≤","‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏°‡πà‡∏ñ‡∏ô‡∏±‡∏î‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÅ‡∏ï‡πà‡∏ù‡∏∂‡∏Å‡∏à‡∏ô‡∏ó‡∏≥‡πÑ‡∏î‡πâ","‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡∏° ‡πÅ‡∏ï‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÑ‡∏î‡πâ","‡πÅ‡∏°‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏£‡πá‡∏ß","‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á"],
                         "mitigate_terms":["‡πÅ‡∏ï‡πà","‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏±‡∏í‡∏ô‡∏≤","‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ","‡∏û‡∏±‡∏í‡∏ô‡∏≤","‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á","‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à‡∏ù‡∏∂‡∏Å","‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°","‡∏à‡∏ô‡∏ó‡∏≥‡πÑ‡∏î‡πâ","‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç"],
                         "mitigation_factor":0.5,"context_window":50}
}
DEFAULT_BASE = {"text_fields":["resume_text","cover_letter_text","skills","activities"],"id_field":"candidate_id","label_field":"label"}

ui_css = """
<style>
:root { --brand:#0EA5E9; --brand2:#22D3EE; }
.hero{background:linear-gradient(135deg,#0284C7,#22D3EE);color:#fff;padding:38px 28px 30px 28px;border-radius:16px;box-shadow:0 10px 25px rgba(14,165,233,.25);margin-bottom:18px;}
.kpi{background:#fff;border:1px solid #e6f4ff;border-radius:14px;padding:14px 16px;box-shadow:0 4px 14px rgba(14,165,233,.08)}
.kpi h4{margin:0 0 8px 0;font-size:14px;color:#0b6aa7}
.kpi .v{font-size:24px;font-weight:700}
</style>
"""
st.markdown(ui_css, unsafe_allow_html=True)
st.markdown('<div class="hero"><h3>üìÑ ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ AI</h3></div>', unsafe_allow_html=True)

# ---------- sidebar ----------
with st.sidebar:
    st.markdown(f"üë§ HR: {st.session_state.username}")
    if st.button("Logout"):
        logout()

    st.header("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏Å / ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
    department = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ú‡∏ô‡∏Å", list(DEPARTMENTS_CFG.keys()))
    st.slider("‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ú‡πà‡∏≤‡∏ô (Pass) ‚â•", 0.10, 0.90, step=0.01, key="pass_cut")
    pass_cut = st.session_state.pass_cut

    enable_email = st.toggle("‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏à‡πâ‡∏á‡∏ú‡∏•‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏ó‡∏≤‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•", value=False)
    if enable_email:
        provider = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ SMTP", ["Gmail", "Outlook/Hotmail"])
        if provider == "Gmail":
            smtp_host_default, port_default, ssl_default = "smtp.gmail.com", 587, False
        else:
            smtp_host_default, port_default, ssl_default = "smtp.office365.com", 587, False

        smtp_host = st.text_input("SMTP Host", value=smtp_host_default)
        smtp_port = st.number_input("Port", min_value=1, max_value=65535, value=port_default)
        use_ssl = st.toggle("‡πÉ‡∏ä‡πâ SSL (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏û‡∏≠‡∏£‡πå‡∏ï 465)", value=ssl_default)
        smtp_user = st.text_input("Username (‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏ú‡∏π‡πâ‡∏™‡πà‡∏á)")
        smtp_pass = st.text_input("Password/App Password", type="password")
        from_name = st.text_input("From Name", value="HR Team")
        from_email = st.text_input("From Email (‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Username)", value=smtp_user)

        subj_pass = st.text_input("‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡∏ú‡πà‡∏≤‡∏ô)", value="[‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó] ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏á‡∏≤‡∏ô ‚Äì ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô")
        subj_fail = st.text_input("‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô)", value="[‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó] ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏á‡∏≤‡∏ô ‚Äì ‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á")

        default_pass = textwrap.dedent("""\
‡πÄ‡∏£‡∏µ‡∏¢‡∏ô {{name}} ({{candidate_id}})
‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á {{department}} : '‡∏ú‡πà‡∏≤‡∏ô'
‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°: {{score}}
‡∏ó‡∏µ‡∏°‡∏á‡∏≤‡∏ô‡∏à‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏à‡πâ‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞
""").strip()
        default_fail = textwrap.dedent("""\
‡πÄ‡∏£‡∏µ‡∏¢‡∏ô {{name}} ({{candidate_id}})
‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á {{department}} : '‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô'
‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏´‡∏•‡∏±‡∏Å: {{reasons}}
‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à ‡πÅ‡∏•‡∏∞‡∏´‡∏ß‡∏±‡∏á‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏£‡πà‡∏ß‡∏°‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏Ñ‡∏£‡∏±‡∏ö/‡∏Ñ‡πà‡∏∞
""").strip()
        msg_tpl_pass = st.text_area("‡πÄ‡∏ó‡∏°‡πÄ‡∏û‡∏•‡∏ï (‡∏ú‡πà‡∏≤‡∏ô)", value=default_pass, height=140)
        msg_tpl_fail = st.text_area("‡πÄ‡∏ó‡∏°‡πÄ‡∏û‡∏•‡∏ï (‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô)", value=default_fail, height=160)

        st.markdown("---")

        def _send_email(h, p, ssl_on, user, pwd, fname, femail, to_email, sub, body_text):
            msg = MIMEText(body_text, _charset="utf-8")
            msg["Subject"] = sub
            msg["From"] = formataddr((fname, femail))
            msg["To"] = to_email
            msg["Date"] = formatdate(localtime=True)
            msg["Message-Id"] = make_msgid()
            if ssl_on:
                server = smtplib.SMTP_SSL(h, int(p))
            else:
                server = smtplib.SMTP(h, int(p))
                try: server.starttls()
                except Exception: pass
            try:
                if user: server.login(user, pwd)
                refused = server.sendmail(femail, [to_email], msg.as_string())
                ok = (len(refused) == 0)
                return ok, ("" if ok else str(refused))
            finally:
                try: server.quit()
                except Exception: pass

        test_to = st.text_input("‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏≠‡∏µ‡πÄ‡∏°‡∏•", value=smtp_user or "")
        if st.button("‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡πà‡∏á‡πÄ‡∏°‡∏•"):
            ok, info = _send_email(smtp_host, smtp_port, use_ssl, smtp_user, smtp_pass,
                                   from_name, from_email or smtp_user, clean_email(test_to),
                                   "SMTP Test ‚Ä¢ AI Screening", "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö")
            if ok: st.success(f"‡∏™‡πà‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÑ‡∏õ‡∏ó‡∏µ‡πà {clean_email(test_to)}")
            else: st.error(f"‡∏™‡πà‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: refused {info}")

# ---------- ML ----------
def build_pipeline(text_fields):
    text_vect = TfidfVectorizer(tokenizer=thai_tokenize, token_pattern=None, ngram_range=(1,2), min_df=1, max_df=0.95)
    text_transformer = Pipeline(steps=[
        ("concat", FunctionTransformer(concat_text_df, kw_args={"fields": tuple(text_fields)}, validate=False)),
        ("tfidf", text_vect)
    ])
    pre = ColumnTransformer(
        transformers=[
            ("text", text_transformer, text_fields),
            ("exp", FunctionTransformer(combine_exp_func, validate=False), ["years_experience","months_experience"]),
            ("edu", EducationEncoder(), ["education_level"]),
            ("age", "passthrough", ["age"])
        ],
        remainder="drop"
    )
    clf = LogisticRegression(max_iter=300)
    return Pipeline(steps=[("pre", pre), ("clf", clf)])

def _apply_global_knockout(blob, cfg):
    gk = cfg.get("global_knockout", DEFAULT_RULES["global_knockout"])
    weights = cfg.get("global_knockout_weights", DEFAULT_RULES["global_knockout_weights"])
    cap = cfg.get("global_knockout_cap", DEFAULT_RULES["global_knockout_cap"])
    mitig = cfg.get("global_mitigation", DEFAULT_RULES["global_mitigation"])
    wlist = [normalize_text(x) for x in mitig.get("whitelist_phrases", [])]
    mterms = [normalize_text(x) for x in mitig.get("mitigate_terms", [])]
    factor = float(mitig.get("mitigation_factor", 0.5))
    ctx = int(mitig.get("context_window", 50))
    penalty = 0.0
    hits = []
    for level in ["hard","soft","review"]:
        for phrase in gk.get(level, []):
            p = normalize_text(phrase)
            if not p: continue
            pos = blob.find(p)
            if pos == -1: continue
            if any(normalize_text(w) in blob for w in wlist):
                hits.append(f"{p}~whitelist"); continue
            start = max(0, pos - ctx); end = min(len(blob), pos + len(p) + ctx)
            window = blob[start:end]
            weight = float(weights.get(level, 0.0))
            if any(t in window for t in mterms) and weight < 0:
                weight *= factor; hits.append(f"{p}:{level}*{factor:.1f}")
            else:
                hits.append(f"{p}:{level}")
            penalty += weight
    if penalty < cap: penalty = cap
    return penalty, hits

def rule_score(row, cfg):
    def _to_num(x):
        try: return float(x)
        except: return 0.0
    w = cfg.get("rule_weights", DEFAULT_RULES["rule_weights"])
    reasons, score = [], 0.0

    y = _to_num(row.get("years_experience", 0))
    m = _to_num(row.get("months_experience", 0))
    total = y + m/12.0
    if total < cfg["min_years_experience"]:
        reasons.append(f"‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå {total:.1f} ‡∏õ‡∏µ < {cfg['min_years_experience']} ‡∏õ‡∏µ"); score += w.get("exp_under", -1.0)
    else:
        reasons.append(f"‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå {total:.1f} ‡∏õ‡∏µ ‚â• ‡πÄ‡∏Å‡∏ì‡∏ë‡πå"); score += w.get("exp_meet", 0.2)

    if encode_education(row.get("education_level","")) < encode_education(cfg["min_education_level"]):
        reasons.append(f"‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ < {cfg['min_education_level']}"); score += w.get("edu_under", -1.0)

    skills = set(split_skills(row.get("skills","")))
    miss = [s for s in cfg["must_have_skills"] if s not in skills]
    if miss:
        reasons.append("‡∏Ç‡∏≤‡∏î‡∏™‡∏Å‡∏¥‡∏•‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: "+", ".join(miss)); score += w.get("must_missing", -1.5)
    else:
        reasons.append("‡∏Ñ‡∏£‡∏ö‡∏™‡∏Å‡∏¥‡∏•‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"); score += w.get("must_all", 0.5)

    blob = " ".join([normalize_text(str(row.get(f,""))) for f in cfg["text_fields"]])

    gk_pen, gk_hits = _apply_global_knockout(blob, cfg)
    if gk_hits: reasons.append("‡∏Ñ‡∏≥‡∏ï‡πâ‡∏≠‡∏á‡∏´‡πâ‡∏≤‡∏°‡∏£‡∏ß‡∏°: " + ", ".join(gk_hits))
    score += gk_pen

    for phrase in cfg.get("knockout_phrases", []):
        if normalize_text(phrase) in blob:
            reasons.append(f"‡∏Ñ‡∏≥‡∏ï‡πâ‡∏≠‡∏á‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: {phrase}"); score += w.get("knockout", -2.0)

    training_indicators = cfg.get("training_indicators", DEFAULT_RULES["training_indicators"])
    ind_alt = "(" + "|".join(map(re.escape, training_indicators)) + ")"
    for s in cfg.get("must_have_skills", []):
        s_esc = re.escape(s)
        ps1 = re.compile(ind_alt + r".{0,40}\b" + s_esc + r"\b")
        ps2 = re.compile(r"\b" + s_esc + r"\b.{0,40}" + ind_alt)
        if ps1.search(blob) or ps2.search(blob):
            reasons.append(f"{s}: ‡∏û‡∏ö‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏≤‡∏£‡∏≠‡∏ö‡∏£‡∏°/‡∏Ñ‡∏≠‡∏£‡πå‡∏™"); score += w.get("training_ctx", -0.5)

    nice = [s for s in cfg.get("nice_to_have_skills", []) if s in skills]
    if nice:
        reasons.append("‡∏°‡∏µ‡∏™‡∏Å‡∏¥‡∏•‡πÄ‡∏™‡∏£‡∏¥‡∏°: "+", ".join(nice)); score += w.get("nice_each", 0.3) * len(nice)

    low_exp = max(0.5, cfg.get("min_years_experience",0)/2)
    for s in cfg.get("must_have_skills", []):
        if s in skills and total < low_exp:
            reasons.append(f"‡∏°‡∏µ {s} ‡πÅ‡∏ï‡πà‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏ß‡∏° < {low_exp:.1f} ‡∏õ‡∏µ"); score += w.get("low_exp_skill", -0.3)

    age_val = _to_num(row.get("age", -1))
    age_range = cfg.get("age_range", DEFAULT_RULES.get("default_age_range", [18,60]))
    if age_val >= 0:
        if not (age_range[0] <= age_val <= age_range[1]):
            reasons.append(f"‡∏≠‡∏≤‡∏¢‡∏∏ {int(age_val)} ‡∏õ‡∏µ ‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á ({age_range[0]}‚Äì{age_range[1]})"); score += w.get("age_out", -1.0)
        else:
            reasons.append(f"‡∏≠‡∏≤‡∏¢‡∏∏ {int(age_val)} ‡∏õ‡∏µ ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î"); score += w.get("age_in", 0.2)
    else:
        reasons.append("‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏≠‡∏≤‡∏¢‡∏∏ (‡πÑ‡∏°‡πà‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)")

    acts = normalize_text(str(row.get("activities", "")))
    aw = cfg.get("activity_weights", DEFAULT_RULES.get("activity_weights", {}))
    max_bonus = cfg.get("max_activity_bonus", DEFAULT_RULES.get("max_activity_bonus", 0.0))
    is_training_like_activity = any(normalize_text(ind) in acts for ind in training_indicators)
    bonus = 0.0; hits=[]
    for k, wt in aw.items():
        if normalize_text(k) in acts:
            hits.append(f"{k}+{wt}"); bonus += float(wt)
    if bonus > 0:
        if is_training_like_activity:
            reasons.append("‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏≠‡∏ö‡∏£‡∏°: ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏ö‡∏ô‡∏±‡∏™‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°")
        else:
            bonus = min(bonus, max_bonus)
            reasons.append("‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°: " + ", ".join(hits) + (f" (‡∏£‡∏ß‡∏° +{bonus:.1f})" if bonus>0 else "")); score += bonus

    return score, reasons

def bucket_level(final_priority, pass_cut):
    return "‡∏ú‡πà‡∏≤‡∏ô" if final_priority >= pass_cut else "‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô"

# ---------- tabs ----------
tab_train, tab_screen = st.tabs(["‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (CSV)", "‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£ (CSV/PDF)"])

with tab_train:
    c1, c2 = st.columns([2,1])
    with c1:
        train_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ label 0/1)", type=["csv"], key="train_csv")
    with c2:
        train_btn = st.button("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô", type="primary", use_container_width=True)
        if (MODEL_DIR / "model.joblib").exists():
            st.download_button("‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•", data=open(MODEL_DIR / "model.joblib","rb"),
                               file_name="model.joblib", use_container_width=True)
    if train_btn and train_file is not None:
        df = pd.read_csv(train_file)
        need = [*"resume_text cover_letter_text skills activities".split(), "years_experience", "education_level", "label"]
        miss = [c for c in need if c not in df.columns]
        if "months_experience" not in df.columns: df["months_experience"] = 0
        if "age" not in df.columns: df["age"] = -1
        if "activities" not in df.columns: df["activities"] = ""
        if miss:
            st.error(f"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: {miss}")
        else:
            y = df["label"]
            pipe = build_pipeline(["resume_text","cover_letter_text","skills","activities"])
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô..."):
                pipe.fit(df, y)
                atomic_joblib_dump({"pipeline": pipe, "config": DEFAULT_BASE}, MODEL_DIR / "model.joblib", compress=3)
            st.success("‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

with tab_screen:
    c1, c2, c3 = st.columns([2,2,1])
    with c1:
        ftype = st.radio("‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå", ["CSV (‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ô)", "PDF (‡∏ó‡∏µ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå)"], horizontal=True)
        infile = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå", type=["csv"] if ftype.startswith("CSV") else ["pdf"], key="screen_file")
        if ftype.endswith("PDF") and not PDF_OK:
            st.info("‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyMuPDF: pip install PyMuPDF")
    with c2:
        up_model = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (.joblib) ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î", type=["joblib"], key="mup")
        model = None
        if up_model is not None:
            try:
                model = joblib.load(up_model); st.success("‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            except Exception as e:
                st.error(f"‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        if model is None and (MODEL_DIR / "model.joblib").exists():
            model = safe_load_joblib(MODEL_DIR / "model.joblib")
            if model is None:
                st.error("‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏™‡∏µ‡∏¢ ‡πÇ‡∏õ‡∏£‡∏î‡∏ù‡∏∂‡∏Å‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà")
        if model is None and not (MODEL_DIR / "model.joblib").exists():
            st.warning("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÇ‡∏õ‡∏£‡∏î‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö‡πÅ‡∏£‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î .joblib")
    with c3:
        run_btn = st.button("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô", type="primary", use_container_width=True)

    def _render_template(tpl, ctx):
        out = tpl
        for k, v in ctx.items():
            out = out.replace(f"{{{{{k}}}}}", str(v))
        return out

    if run_btn and infile is not None and model is not None:
        pipe = model["pipeline"]
        if ftype.endswith("PDF"):
            pdf_text = extract_text_from_pdf(infile)
            df = pd.DataFrame([{
                "candidate_id": infile.name, "resume_text": pdf_text, "cover_letter_text": "",
                "years_experience": 0, "months_experience": 0, "education_level": "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏",
                "skills": "", "activities": "", "age": -1, "email": "", "name": "‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£"
            }])
        else:
            df = pd.read_csv(infile)
            if "months_experience" not in df.columns: df["months_experience"] = 0
            if "age" not in df.columns: df["age"] = -1
            if "activities" not in df.columns: df["activities"] = ""
            if "email" not in df.columns: df["email"] = ""
            if "name" not in df.columns: df["name"] = "‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£"

        need = ["candidate_id","resume_text","cover_letter_text","skills","activities","years_experience","education_level"]
        miss = [c for c in need if c not in df.columns]
        if miss:
            st.error(f"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: {miss}")
        else:
            proba = pipe.predict_proba(df)[:, 1]
            rows = []
            for i, row in df.iterrows():
                # ‚Üê‚Üê ‡πÅ‡∏Å‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢: ‡∏õ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢ '}' ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà ']'
                merged_cfg = {**DEFAULT_RULES, **DEPARTMENTS_CFG[department], **DEFAULT_BASE}
                rscore, reasons = rule_score(row, merged_cfg)
                final = 0.7 * float(proba[i]) + 0.3 * (1 / (1 + np.exp(-rscore)))

                def _to_num(x):
                    try: return float(x)
                    except: return 0.0

                level = bucket_level(final, pass_cut)
                y_exp = _to_num(row.get("years_experience", 0)); m_exp = _to_num(row.get("months_experience", 0))
                total_months = int(round(y_exp * 12 + m_exp))
                y_show = total_months // 12; m_show = total_months % 12
                rows.append({
                    "candidate_id": row.get("candidate_id", i),
                    "name": row.get("name","‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£"),
                    "email": clean_email(row.get("email","")),
                    "experience_text": f"{int(y_show)} ‡∏õ‡∏µ {int(m_show)} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô",
                    "age": (int(row.get("age", -1)) if pd.notna(row.get("age", -1)) else -1),
                    "predicted_fit": round(float(proba[i]), 4),
                    "rule_score": round(float(rscore), 2),
                    "final_priority": round(float(final), 4),
                    "predicted_level": level,
                    "reasons": "; ".join(reasons)
                })
            out = pd.DataFrame(rows).sort_values("final_priority", ascending=False).reset_index(drop=True)
            out["email"] = out["email"].apply(clean_email)

            m1, m2, m3 = st.columns(3)
            m1.markdown(f'<div class="kpi"><h4>‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£</h4><div class="v">{len(out)}</div></div>', unsafe_allow_html=True)
            m2.markdown(f'<div class="kpi"><h4>‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î</h4><div class="v">{out["final_priority"].max():.2f}</div></div>', unsafe_allow_html=True)
            m3.markdown(f'<div class="kpi"><h4>‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô</h4><div class="v">{out["final_priority"].mean():.2f}</div></div>', unsafe_allow_html=True)

            show_only_pass = st.toggle("‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå", value=False)
            if show_only_pass: out = out[out["predicted_level"] == "‡∏ú‡πà‡∏≤‡∏ô"].reset_index(drop=True)

            default_cols = ["candidate_id","name","email","experience_text","age","final_priority","predicted_level","predicted_fit","rule_score","reasons"]
            chosen_cols = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á", options=list(out.columns),
                                         default=[c for c in default_cols if c in out.columns])
            if chosen_cols: out = out[chosen_cols]

            st.dataframe(out, use_container_width=True, hide_index=True)
            st.download_button("‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏• (CSV)", data=out.to_csv(index=False).encode("utf-8"),
                               file_name="screened_pass_fail.csv", use_container_width=True)

            st.subheader("‡πÅ‡∏à‡πâ‡∏á‡∏ú‡∏•‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏ó‡∏≤‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•")
            if enable_email:
                email_col, name_col = "email", "name"
                max_reasons = st.slider("‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô)", 1, 10, 3)
                preview_n = st.number_input("‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", min_value=1, max_value=max(1, len(out)), value=min(3, len(out)))

                def _mk_message(rowx):
                    ctx = {
                        "name": str(rowx.get(name_col, "‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£")).strip() or "‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£",
                        "candidate_id": rowx.get("candidate_id",""),
                        "department": department,
                        "score": f"{rowx.get('final_priority',0):.2f}",
                        "reasons": "; ".join(str(rowx.get("reasons","")).split("; ")[:max_reasons])
                    }
                    passed = (rowx.get("predicted_level") == "‡∏ú‡πà‡∏≤‡∏ô")
                    subject = subj_pass if passed else subj_fail
                    body_tpl = msg_tpl_pass if passed else msg_tpl_fail
                    return _render_template(subject, ctx), _render_template(body_tpl, ctx)

                st.markdown("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•")
                for i in range(int(preview_n)):
                    r = out.iloc[i]
                    addr = clean_email(r.get(email_col, ""))
                    subj, body = _mk_message(r)
                    st.code(f"To: {addr}\nSubject: {subj}\n\n{body}")

                out["email_valid"] = out[email_col].apply(is_valid_email)
                bad_rows = out[~out["email_valid"]]
                if len(bad_rows) > 0:
                    st.error(f"‡∏û‡∏ö‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡πà‡∏á {len(bad_rows)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á/‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏¥‡∏î/‡∏ß‡πà‡∏≤‡∏á) ‚Äî ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏Ç‡πâ‡∏≤‡∏°")
                    st.dataframe(bad_rows[["candidate_id","name","email"]], use_container_width=True, hide_index=True)

                test_idx = st.selectbox("‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏¢ (‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á):", list(range(len(out))) or [0])
                if st.button("‡∏™‡πà‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏≤‡∏¢‡∏ô‡∏µ‡πâ"):
                    r = out.iloc[int(test_idx)]
                    to_email = clean_email(r.get(email_col, ""))
                    subj, body = _mk_message(r)
                    ok, info = _send_email(st.session_state.get("smtp_host", smtp_host), st.session_state.get("smtp_port", smtp_port),
                                           st.session_state.get("use_ssl", use_ssl), smtp_user, smtp_pass,
                                           from_name, from_email or smtp_user, to_email, subj, body)
                    if ok: st.success(f"‡∏™‡πà‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÑ‡∏õ‡∏ó‡∏µ‡πà {to_email}")
                    else: st.error(f"‡∏™‡πà‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: refused {info}")

                do_send = st.button("‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πÅ‡∏à‡πâ‡∏á‡∏ú‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", type="primary")
                if do_send:
                    sent, failed, skipped = 0, 0, 0
                    logs = []
                    for _, r in out.iterrows():
                        to_email = clean_email(r.get(email_col, ""))
                        if not is_valid_email(to_email):
                            skipped += 1
                            logs.append({"candidate_id": r["candidate_id"], "to": to_email, "status": "SKIPPED", "reason": "invalid/demo domain"})
                            continue
                        subj, body = _mk_message(r)
                        ok, info = _send_email(smtp_host, smtp_port, use_ssl, smtp_user, smtp_pass,
                                               from_name, from_email or smtp_user, to_email, subj, body)
                        if ok:
                            sent += 1
                            logs.append({"candidate_id": r["candidate_id"], "to": to_email, "status": "SENT", "reason": ""})
                        else:
                            failed += 1
                            logs.append({"candidate_id": r["candidate_id"], "to": to_email, "status": "FAILED", "reason": f"refused: {info}"})
                        time.sleep(1.0)
                    st.success(f"‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {sent} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£, ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß {failed} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£, ‡∏Ç‡πâ‡∏≤‡∏° {skipped} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                    st.dataframe(pd.DataFrame(logs), use_container_width=True, hide_index=True)
            else:
                st.info("‡πÄ‡∏õ‡∏¥‡∏î‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå '‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏à‡πâ‡∏á‡∏ú‡∏•‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏ó‡∏≤‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•' ‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ")

